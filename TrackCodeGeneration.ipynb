{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import Image, HTML\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook assumes the following files are available:\n",
    "\n",
    "- project-to-commit (p2c) map for the hackathon projects. \n",
    "- commit-to-blob (c2b) map for the hackathon commits \n",
    "- blob-to-author (b2a) map for the hackathon blobs \n",
    "- project-to-author (p2a) map for the hackathon projects \n",
    "\n",
    "- DEVPOST project-to-wocURL information (woc-urls.csv) csv file \n",
    "- DEVPOST project information (projects-incl-hackathon.csv) csv file \n",
    "\n",
    "- Code Blobs data (prog_blobs) file \n",
    "\n",
    "- project-to-author (p2a) map for other projects \n",
    "- commit-to-project (c2P) map for first commits of each hackathon blob \n",
    "- author-to-author (a2A) map for the first author of each hackathon blob \n",
    "\n",
    "\n",
    "See README for corresponding commands using World of Code tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "HackDF = pd.read_csv('SampleData/projects-incl-hackathon.csv',sep=';')\n",
    "hbacDF = pd.read_csv('SampleData/b2a.csv',sep=';', encoding = \"ISO-8859-1\")\n",
    "hcbDF = pd.read_csv('SampleData/c2b.csv',sep=';')\n",
    "hpcDF = pd.read_csv('SampleData/p2c.csv',sep=';')\n",
    "wocURLDF = pd.read_csv('SampleData/woc-urls.csv',sep=',')\n",
    "hpaDF = pd.read_csv('SampleData/hp2a.csv',sep=';')\n",
    "p2aDF = pd.read_csv('SampleData/p2aFirst.csv', sep= ';')\n",
    "c2PLinesDF = pd.read_csv('SampleData/c2PFirst.csv', sep=';')\n",
    "AuthorsMergeMap = pd.read_csv('SampleData/AuthorsMergeMap', sep=';')\n",
    "prog_blobs = pd.read_csv('SampleData/prog_blobs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for TimingFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare hackathon info\n",
    "df = HackDF[['id','hackathon-id','hackathon-end-date']]\n",
    "df.rename(columns = {'id':'devpostID', 'hackathon-id':'hackathonID', 'hackathon-end-date':'hackathonEndDate'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare hackathon info ( Calculate Start Date)\n",
    "\n",
    "df['hackathonStartDate'] = df.apply(lambda row: datetime.strptime(row.hackathonEndDate, '%Y-%m-%d') - timedelta(days=2), axis=1)\n",
    "HackDuration = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('HackathonDuration.csv', index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only Code Blobs by Github Lingustic tool\n",
    "\n",
    "hbacDFWCommon = pd.merge(hbacDF, prog_blobs, how='inner', left_on=['BlobHash'], right_on=['Blob'])\n",
    "hbacDFWCommon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Blobs with Hackathon Commits\n",
    "\n",
    "BC = pd.merge(hbacDFWCommon, hcbDF, how='inner', left_on=['BlobHash'], right_on=['BlobHash'])[['BlobHash','CommitHash','FirstTimestamp','FirstAuthorID','FirstCommitHash']]\n",
    "BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join BC dataset with Hackathon projects\n",
    "\n",
    "BCP = pd.merge(BC, hpcDF, how='inner', left_on=['CommitHash'], right_on=['CommitHash'])[['BlobHash','ProjectID','FirstTimestamp','FirstAuthorID','FirstCommitHash']].drop_duplicates()\n",
    "BCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with wocURLs\n",
    "\n",
    "BCP_DevPost = pd.merge(BCP, wocURLDF, how='inner', left_on=['ProjectID'], right_on=['ProjectID'])[['devpost_id','hackathon_id','ProjectID','BlobHash','FirstTimestamp','FirstAuthorID','FirstCommitHash']].drop_duplicates()\n",
    "\n",
    "BCP_DevPost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Join with hackathon durations\n",
    "compareDF = pd.merge(BCP_DevPost, HackDuration, how='inner', left_on=['devpost_id','hackathon_id'], right_on = ['devpostID','hackathonID'])[['devpost_id','hackathon_id','ProjectID','BlobHash','FirstTimestamp','FirstAuthorID','FirstCommitHash','hackathonStartDate','hackathonEndDate']].drop_duplicates()\n",
    "compareDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix timestamps for start/end dates\n",
    "\n",
    "def addMaxTime(dcol):\n",
    "    return str(dcol) + ' 23:59:59'\n",
    "    \n",
    "def addMinTime(dcol):\n",
    "    return str(dcol) + ' 00:00:00'\n",
    "\n",
    "compareDF['hackathonEndDate'] = compareDF['hackathonEndDate'].apply(addMaxTime)\n",
    "\n",
    "compareDF['hackathonStartDate'] =  pd.to_datetime(compareDF['hackathonStartDate'], format='%Y-%m-%d %H:%M:%S')\n",
    "compareDF['hackathonEndDate'] =  pd.to_datetime(compareDF['hackathonEndDate'], format='%Y-%m-%d %H:%M:%S')\n",
    "# compareDF.info()\n",
    "compareDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TimingFlag\n",
    "\n",
    "%%time\n",
    "\n",
    "def compareDates(row):\n",
    "    hackathonStartDate = datetime.strptime(str(row.hackathonStartDate), '%Y-%m-%d %H:%M:%S')\n",
    "    hackathonEndDate = datetime.strptime(str(row.hackathonEndDate), '%Y-%m-%d %H:%M:%S')\n",
    "    FirstTimestamp = datetime.strptime(str(row.FirstTimestamp), '%Y-%m-%d %H:%M:%S')\n",
    "    if (hackathonStartDate < FirstTimestamp < hackathonEndDate):\n",
    "        return 2            # Between\n",
    "    elif (FirstTimestamp > hackathonEndDate):\n",
    "        return 3            # After\n",
    "    else:\n",
    "        return 1            # Before\n",
    "    \n",
    "def iterrows_impl(df):\n",
    "    return pd.Series(\n",
    "        compareDates(row)     \n",
    "        for row in df.itertuples()\n",
    "    )\n",
    "  \n",
    "\n",
    "compareDF['TimingFlag'] = pd.Series(iterrows_impl(compareDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping for results (Count per TimingFlag)\n",
    "\n",
    "result1 = compareDF[['BlobHash','TimingFlag']].groupby(['TimingFlag']).agg(['count'])\n",
    "result1['Percentage'] = result1.apply(lambda x: 100 * x / float(x.sum()))\n",
    "result1 = result1.reset_index()\n",
    "result1.columns = ['TimingFlag','BlobHash','Percentage']\n",
    "result1\n",
    "# If Before then TimingFlag = 1\n",
    "# If between then TimingFlag = 2\n",
    "# If After then TimingFlag = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "import numpy as np \n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "plt.figure(1, figsize=(20,20)) \n",
    "cmap = plt.get_cmap('Spectral')\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, 8)]\n",
    "\n",
    "# Creating dataset \n",
    "Labels = result1[['TimingFlag']].values #['Before', 'During', 'After'] \n",
    "data = result1[['BlobHash']].values.flatten() \n",
    "perc = result1[['Percentage']].values\n",
    "  \n",
    "# Creating plot \n",
    "the_grid = GridSpec(2, 2)\n",
    "plt.subplot(the_grid[0, 1], aspect=1, title='Percentage based on Timing Flag')\n",
    "plt.pie(data, labels = Labels, autopct='%1.1f%%', shadow=True, colors=colors) \n",
    "  \n",
    "# show plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "x = result1.sort_values(by=['Percentage'])[['TimingFlag']].values #['During','After', 'Before']\n",
    "data = result1.sort_values(by=['Percentage'])[['Percentage']].values.flatten() \n",
    "\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "\n",
    "plt.barh(x_pos, data, color='green')\n",
    "plt.ylabel(\"Blob generation category\")\n",
    "plt.xlabel(\"Percentage\")\n",
    "plt.title(\"Percentage based on Timing Flag\")\n",
    "\n",
    "plt.yticks(x_pos, x)\n",
    "\n",
    "for i, v in enumerate(data):\n",
    "    plt.text(v +0.5, i -0.1, str(round(v,2)) + '%', color='Black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "x = result1.sort_values(by=['Percentage'])[['TimingFlag']].values #['During','After', 'Before']\n",
    "data = result1.sort_values(by=['Percentage'])[['BlobHash']].values.flatten() \n",
    "\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "\n",
    "plt.barh(x_pos, data, color='green')\n",
    "plt.ylabel(\"Blob generation category\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.title(\"Blob Count based on Timing Flag\")\n",
    "\n",
    "plt.yticks(x_pos, x)\n",
    "\n",
    "for i, v in enumerate(data):\n",
    "    plt.text(v +0.5, i -0.1, str(round(v,2)) , color='Black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for AuthorFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2aDF = p2aDF.drop_duplicates()\n",
    "p2aDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2PLinesDF = c2PLinesDF.drop_duplicates()\n",
    "c2PLinesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to add hackathon project authors\n",
    "%%time\n",
    "\n",
    "compareDF2 = pd.merge(compareDF, hpaDF, how='inner', left_on=['ProjectID'], right_on=['ProjectID'])\n",
    "compareDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge author name aliases\n",
    "compareDF22 = pd.merge(compareDF2, AuthorsMergeMap,how='left', left_on=['FirstAuthorID'], right_on=['AuthorsMap'])\n",
    "compareDF22['FirstAuthorL'] = compareDF22['FirstAuthorID'] +','+ compareDF22['AuthorAlias'].fillna('')\n",
    "del compareDF22['AuthorsMap']\n",
    "del compareDF22['AuthorAlias']\n",
    "compareDF22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to get projects for each initial commit of a blob\n",
    "compareDF3 = pd.merge(compareDF22, c2PLinesDF, how='inner', left_on=['FirstCommitHash'], right_on = ['CommitHash'])\n",
    "compareDF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to get the authors for each project\n",
    "compareDF3 = pd.merge(compareDF3, p2aDF, how='inner', left_on=['CProject'], right_on = ['ProjectID'])\n",
    "compareDF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logic to get AuthorFlag\n",
    "%%time\n",
    "        \n",
    "def checkAuthor(row):\n",
    "    AuthorL = str(row.AuthorL).split(\",\")        # Hackathon Team\n",
    "    AuthorL = list(filter(None, AuthorL))\n",
    "    PAuthorL = str(row.PAuthorL).split(\",\")      # Commit Authors from other projects\n",
    "    PAuthorL = list(filter(None, PAuthorL))\n",
    "    FirstAuthorL = str(row.FirstAuthorID).split(\",\")\n",
    "    FirstAuthorL = list(filter(None, FirstAuthorL))\n",
    "    HAuthInteract = list(set(FirstAuthorL) & set(AuthorL))\n",
    "    if (len(HAuthInteract) > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        PAuthorIntersect = list(set(AuthorL) & set(PAuthorL))\n",
    "        if(len(PAuthorIntersect)) > 0:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    \n",
    "def iterrows_impl(df):\n",
    "    return pd.Series(\n",
    "        checkAuthor(row)     \n",
    "        for row in df.itertuples()\n",
    "    )\n",
    "  \n",
    "\n",
    "compareDF3['AuthorFlag'] = pd.Series(iterrows_impl(compareDF3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataframe\n",
    "compareDF3[['devpost_id','devpost_id','ProjectID_x','hackathonStartDate','hackathonEndDate','BlobHash','TimingFlag','AuthorFlag']].to_csv('compareDF3_20210104.csv',sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change AuthorFlag to string\n",
    "compareDF3['AuthorFlag']= compareDF3['AuthorFlag'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate AuthorFlag , since a commit can be used in many projects in c2P\n",
    "finalResultDF = compareDF3[['devpost_id','ProjectID_x','hackathonStartDate','hackathonEndDate','BlobHash','TimingFlag','AuthorFlag']].groupby(['devpost_id','ProjectID_x','hackathonStartDate','hackathonEndDate','BlobHash','TimingFlag']).agg({'AuthorFlag':lambda x : ','.join(set(x))}).reset_index()\n",
    "finalResultDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logic to get AuthorFlagMin\n",
    "\n",
    "def checkUsageMin(row):\n",
    "    AuthorFlagL = str(row.AuthorFlag).split(\",\")        \n",
    "    AuthorFlagMin = min(AuthorFlagL)\n",
    "    return AuthorFlagMin\n",
    "\n",
    "\n",
    "    \n",
    "def iterrows_impl(df):\n",
    "    return pd.Series(\n",
    "        checkUsageMin(row)     \n",
    "        for row in df.itertuples()\n",
    "    )\n",
    "  \n",
    "\n",
    "finalResultDF['AuthorFlagMin'] = pd.Series(iterrows_impl(finalResultDF))\n",
    "\n",
    "finalResultDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "del finalResultDF['AuthorFlag']\n",
    "finalResultDF.rename(columns={'AuthorFlagMin':'AuthorFlag'}, inplace=True)\n",
    "finalResultDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate count for each AuthorFlag\n",
    "\n",
    "result2 = finalResultDF[['BlobHash','AuthorFlag']].groupby(['AuthorFlag']).agg(['count'])\n",
    "\n",
    "result2['Percentage'] = result2.apply(lambda x: 100 * x / float(x.sum()))\n",
    "result2 = result2.reset_index()\n",
    "result2.columns = ['AuthorFlag','BlobHash','Percentage']\n",
    "result2\n",
    "\n",
    "# AuthorFlag = 1   Author is part of the team\n",
    "# AuthorFlag = 2   Author Overlap with the origional project\n",
    "# AuthorFlag = 3   Others\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "import numpy as np \n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "plt.figure(1, figsize=(20,20)) \n",
    "cmap = plt.get_cmap('Spectral')\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, 8)]\n",
    "\n",
    "# Creating dataset \n",
    "Labels = ['Same Author', 'CoAuthor', 'Other Author'] \n",
    "data = result2[['BlobHash']].values.flatten() \n",
    "  \n",
    "# Creating plot \n",
    "the_grid = GridSpec(2, 2)\n",
    "plt.subplot(the_grid[0, 1], aspect=1, title='Percentage based on Author Flag')\n",
    "plt.pie(data, labels = Labels, autopct='%1.1f%%', shadow=True, colors=colors) \n",
    "  \n",
    "# show plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "x = result2.sort_values(by=['Percentage'])[['AuthorFlag']].values #['CoAuthor', 'Other Author', 'Same Author'] \n",
    "data = result2.sort_values(by=['Percentage'])[['Percentage']].values.flatten() \n",
    "\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "\n",
    "plt.barh(x_pos, data, color='black')\n",
    "plt.ylabel(\"Blob generation category\")\n",
    "plt.xlabel(\"Percentage\")\n",
    "plt.title(\"Percentage based on Author Flag\")\n",
    "\n",
    "plt.yticks(x_pos, x)\n",
    "\n",
    "for i, v in enumerate(data):\n",
    "    plt.text(v +0.5, i -0.1, str(round(v,2)) + '%', color='Black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalResultDF.to_csv('finalResultDF_20210104.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot table for each hackathon project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby projectID, TimingFlag\n",
    "AnalysisTF = finalResultDF.groupby(['ProjectID_x','TimingFlag']).agg({'BlobHash':'count'}).reset_index()\n",
    "AnalysisTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pivot Table \n",
    "AnalysisTFPV = pd.pivot_table(AnalysisTF,index=['ProjectID_x'],values=['BlobHash'],columns=['TimingFlag'],aggfunc=[np.sum],fill_value=0).reset_index()\n",
    "AnalysisTFPV.columns = ['ProjectID','Before','During','After']\n",
    "\n",
    "AnalysisTFPV.to_csv('Analysis_TF_Pivot.csv', sep=';',index=False)\n",
    "AnalysisTFPV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot for groupby TimingFlag and AuthorFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = finalResultDF[['TimingFlag','AuthorFlag','BlobHash']].groupby(['TimingFlag','AuthorFlag']).count().reset_index()\n",
    "dd.columns = ['TimingFlag','AuthorFlag','BlobCount']\n",
    "dd['TotalBlobs'] = 6511360  # Total records in the finalResultDF dataframe\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['TimingFlag'].replace({1: \"Before\", 2: \"During\", 3: \"After\"}, inplace=True)\n",
    "dd['AuthorFlag'].replace({\"1\": \"Same Author\", \"2\": \"Co-Author\", \"3\": \"Other Author\"}, inplace=True)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['Ratio'] = round(100*(dd['BlobCount'] / dd['TotalBlobs']),2)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddPV = pd.pivot_table(dd,index=['TimingFlag'],values=['Ratio'],columns=['AuthorFlag'],aggfunc=[np.sum],fill_value=0).reset_index()\n",
    "ddPV.columns = ['TimingFlag','Co-Author','Other Author','Same Author']\n",
    "ddPV.to_csv('RQ1Pivot.csv', sep=';', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
